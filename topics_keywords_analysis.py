import streamlit as st
import itertools
import networkx as nx
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from collections import Counter
import numpy as np

def show_topics_keywords_analysis(data):
    """
    Creates and displays topic and keyword co-occurrence network analysis.
    
    Analyzes relationships between main topics and keywords across letters.
    """
    
    st.subheader("–ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏")
    st.markdown("""
    **–ê–Ω–∞–ª–∏–∑:** –ú—Ä–µ–∂–∞ –Ω–∞ —Å—ä–≤–º–µ—Å—Ç–Ω–æ —Å—Ä–µ—â–∞–Ω–µ –Ω–∞ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏ –≤ –ø–∏—Å–º–∞—Ç–∞  
    **–í—ä–∑–ª–∏:** –û—Å–Ω–æ–≤–Ω–∏ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏  
    **–í—Ä—ä–∑–∫–∏:** –°—ä–≤–º–µ—Å—Ç–Ω–æ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–µ –≤ –µ–¥–Ω–æ –∏ —Å—ä—â–æ –ø–∏—Å–º–æ  
    **–†–∞–∑–º–µ—Ä –Ω–∞ –≤—ä–∑–µ–ª–∞:** –ß–µ—Å—Ç–æ—Ç–∞ –Ω–∞ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–µ
    """)
    
    # Extract topics and keywords data
    topics_data, cooccurrence_data = extract_topics_keywords_data(data)
    
    if not topics_data:
        st.warning("–ù—è–º–∞ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –¥–∞–Ω–Ω–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏.")
        return
    
    # Create tabs for different views
    network_tab, frequency_tab, analysis_tab = st.tabs(["üï∏Ô∏è –ú—Ä–µ–∂–∞", "üìä –ß–µ—Å—Ç–æ—Ç–∞", "üîç –ê–Ω–∞–ª–∏–∑"])
    
    with network_tab:
        show_topics_network(topics_data, cooccurrence_data)
    
    with frequency_tab:
        show_topics_frequency(topics_data)
    
    with analysis_tab:
        show_topics_analysis(topics_data, cooccurrence_data)

def extract_topics_keywords_data(data):
    """
    Extract topics and keywords data from the correspondence data.
    Returns topics data and co-occurrence information.
    """
    letters_topics = []
    all_topics = Counter()
    
    for entry in data:
        topics = set()
        
        # Add main topics
        main_topics = entry.get('main_topics', [])
        for topic in main_topics:
            if topic:
                topic = topic.strip()
                topics.add(topic)
                all_topics[topic] += 1
        
        # Add keywords
        keywords = entry.get('keywords', [])
        for keyword in keywords:
            if keyword:
                keyword = keyword.strip()
                topics.add(keyword)
                all_topics[keyword] += 1
        
        if topics:
            letters_topics.append(topics)
    
    # Build co-occurrence edges
    cooccurrence = Counter()
    for topics in letters_topics:
        for a, b in itertools.combinations(sorted(topics), 2):
            cooccurrence[(a, b)] += 1
    
    return {
        'letters_topics': letters_topics,
        'all_topics': all_topics,
        'topic_frequency': dict(all_topics)
    }, dict(cooccurrence)

def show_topics_network(topics_data, cooccurrence_data):
    """
    Display interactive network of topics and keywords using Plotly.
    """
    st.subheader("–ú—Ä–µ–∂–∞ –Ω–∞ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏")
    
    if not cooccurrence_data:
        st.warning("–ù—è–º–∞ –≤—Ä—ä–∑–∫–∏ –º–µ–∂–¥—É —Ç–µ–º–∏—Ç–µ –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è.")
        return
    
    # Create NetworkX graph
    G = nx.Graph()
    
    # Add edges with weights
    for (topic1, topic2), weight in cooccurrence_data.items():
        G.add_edge(topic1, topic2, weight=weight)
    
    # Set node attributes
    topic_freq = topics_data['topic_frequency']
    nx.set_node_attributes(G, topic_freq, 'frequency')
    
    # Control parameters
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        min_cooccurrence = st.slider(
            "–ú–∏–Ω–∏–º–∞–ª–Ω–æ —Å—ä–≤–º–µ—Å—Ç–Ω–æ —Å—Ä–µ—â–∞–Ω–µ:", 
            1, 
            max(cooccurrence_data.values()) if cooccurrence_data else 5, 
            1,
            key="topics_min_cooccurrence"
        )
        
        layout_algorithm = st.selectbox(
            "–ê–ª–≥–æ—Ä–∏—Ç—ä–º –∑–∞ –ø–æ–¥—Ä–µ–¥–±–∞:",
            ["spring", "circular", "kamada_kawai"],
            index=0,
            key="topics_layout_algorithm"
        )
    
    with col1:
        # Filter edges by minimum co-occurrence
        filtered_edges = [(a, b) for (a, b), w in cooccurrence_data.items() if w >= min_cooccurrence]
        
        if not filtered_edges:
            st.warning("–ù—è–º–∞ –≤—Ä—ä–∑–∫–∏, –∫–æ–∏—Ç–æ –æ—Ç–≥–æ–≤–∞—Ä—è—Ç –Ω–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è.")
            return
        
        # Create filtered graph
        G_filtered = nx.Graph()
        G_filtered.add_edges_from(filtered_edges)
        
        # Calculate layout
        if layout_algorithm == "spring":
            pos = nx.spring_layout(G_filtered, k=1, iterations=50)
        elif layout_algorithm == "circular":
            pos = nx.circular_layout(G_filtered)
        else:  # kamada_kawai
            pos = nx.kamada_kawai_layout(G_filtered)
        
        # Create Plotly figure
        fig = go.Figure()
        
        # Add edges
        edge_x = []
        edge_y = []
        for edge in G_filtered.edges():
            if edge[0] in pos and edge[1] in pos:
                x0, y0 = pos[edge[0]]
                x1, y1 = pos[edge[1]]
                edge_x.extend([x0, x1, None])
                edge_y.extend([y0, y1, None])
        
        fig.add_trace(go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=0.5, color='#888'),
            hoverinfo='none',
            mode='lines'
        ))
        
        # Add nodes
        node_x = []
        node_y = []
        node_text = []
        node_sizes = []
        node_colors = []
        
        for node in G_filtered.nodes():
            if node in pos:
                x, y = pos[node]
                node_x.append(x)
                node_y.append(y)
                
                frequency = topic_freq.get(node, 1)
                connections = len(list(G_filtered.neighbors(node)))
                
                node_text.append(
                    f"<b>{node}</b><br>"
                    f"–ß–µ—Å—Ç–æ—Ç–∞: {frequency}<br>"
                    f"–í—Ä—ä–∑–∫–∏: {connections}"
                )
                
                node_sizes.append(max(20, frequency * 10))
                node_colors.append(frequency)
        
        fig.add_trace(go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            hoverinfo='text',
            hovertext=node_text,
            text=[node for node in G_filtered.nodes() if node in pos],
            textposition="middle center",
            marker=dict(
                size=node_sizes,
                color=node_colors,
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(title="–ß–µ—Å—Ç–æ—Ç–∞"),
                line=dict(width=2, color='black')
            )
        ))
        
        fig.update_layout(
            title='–ú—Ä–µ–∂–∞ –Ω–∞ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏',
            showlegend=False,
            hovermode='closest',
            margin=dict(b=20,l=5,r=5,t=40),
            annotations=[dict(
                text=f"–ü–æ–∫–∞–∑–∞–Ω–∏ {len(G_filtered.nodes())} —Ç–µ–º–∏ —Å –º–∏–Ω–∏–º—É–º {min_cooccurrence} —Å—ä–≤–º–µ—Å—Ç–Ω–∏ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–∏—è",
                showarrow=False,
                xref="paper", yref="paper",
                x=0.005, y=-0.002
            )],
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
        )
        
        st.plotly_chart(fig, width='stretch')

def show_topics_frequency(topics_data):
    """
    Display frequency analysis of topics and keywords.
    """
    st.subheader("–ß–µ—Å—Ç–æ—Ç–∞ –Ω–∞ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏")
    
    topic_freq = topics_data['topic_frequency']
    
    if not topic_freq:
        st.warning("–ù—è–º–∞ –¥–∞–Ω–Ω–∏ –∑–∞ —á–µ—Å—Ç–æ—Ç–∞ –Ω–∞ —Ç–µ–º–∏—Ç–µ.")
        return
    
    # Create frequency DataFrame
    freq_df = pd.DataFrame(
        list(topic_freq.items()),
        columns=['–¢–µ–º–∞/–ö–ª—é—á–æ–≤–∞ –¥—É–º–∞', '–ß–µ—Å—Ç–æ—Ç–∞']
    ).sort_values('–ß–µ—Å—Ç–æ—Ç–∞', ascending=False)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("–¢–æ–ø 20 –Ω–∞–π-—á–µ—Å—Ç–∏ —Ç–µ–º–∏")
        top_topics = freq_df.head(20)
        st.dataframe(top_topics, width='stretch')
    
    with col2:
        st.subheader("–†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–µ—Å—Ç–æ—Ç–∞—Ç–∞")
        fig = px.bar(
            top_topics.head(15),
            x='–ß–µ—Å—Ç–æ—Ç–∞',
            y='–¢–µ–º–∞/–ö–ª—é—á–æ–≤–∞ –¥—É–º–∞',
            orientation='h',
            title='–ù–∞–π-—á–µ—Å—Ç–∏ —Ç–µ–º–∏ –∏ –∫–ª—é—á–æ–≤–∏ –¥—É–º–∏'
        )
        fig.update_yaxes(categoryorder="total ascending")
        st.plotly_chart(fig, width='stretch')
    
    # Statistics
    st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("–û–±—â–æ —Ç–µ–º–∏/–¥—É–º–∏", len(topic_freq))
    
    with col2:
        st.metric("–°—Ä–µ–¥–Ω–∞ —á–µ—Å—Ç–æ—Ç–∞", f"{np.mean(list(topic_freq.values())):.1f}")
    
    with col3:
        st.metric("–ù–∞–π-—á–µ—Å—Ç–∞", max(topic_freq.values()))
    
    with col4:
        unique_topics = sum(1 for freq in topic_freq.values() if freq == 1)
        st.metric("–£–Ω–∏–∫–∞–ª–Ω–∏ (1x)", unique_topics)

def show_topics_analysis(topics_data, cooccurrence_data):
    """
    Show detailed analysis of topic relationships.
    """
    st.subheader("–î–µ—Ç–∞–π–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Ä—ä–∑–∫–∏—Ç–µ")
    
    if not cooccurrence_data:
        st.warning("–ù—è–º–∞ –¥–∞–Ω–Ω–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Ä—ä–∑–∫–∏—Ç–µ.")
        return
    
    # Create co-occurrence DataFrame
    cooc_df = pd.DataFrame([
        {
            '–¢–µ–º–∞ 1': topic1,
            '–¢–µ–º–∞ 2': topic2,
            '–°—ä–≤–º–µ—Å—Ç–Ω–∏ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–∏—è': weight
        }
        for (topic1, topic2), weight in cooccurrence_data.items()
    ]).sort_values('–°—ä–≤–º–µ—Å—Ç–Ω–∏ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–∏—è', ascending=False)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("–ù–∞–π-—Å–∏–ª–Ω–∏ –≤—Ä—ä–∑–∫–∏")
        st.dataframe(cooc_df.head(15), width='stretch')
    
    with col2:
        st.subheader("–†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Å–∏–ª–∞—Ç–∞ –Ω–∞ –≤—Ä—ä–∑–∫–∏—Ç–µ")
        fig = px.histogram(
            cooc_df,
            x='–°—ä–≤–º–µ—Å—Ç–Ω–∏ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–∏—è',
            nbins=20,
            title='–†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Å—ä–≤–º–µ—Å—Ç–Ω–∏—Ç–µ —Å–ø–æ–º–µ–Ω–∞–≤–∞–Ω–∏—è'
        )
        st.plotly_chart(fig, width='stretch')
    
    # Network metrics
    if cooccurrence_data:
        st.subheader("–ú—Ä–µ–∂–æ–≤–∏ –º–µ—Ç—Ä–∏–∫–∏")
        
        G = nx.Graph()
        for (topic1, topic2), weight in cooccurrence_data.items():
            G.add_edge(topic1, topic2, weight=weight)
        
        # Calculate centrality measures
        degree_centrality = nx.degree_centrality(G)
        betweenness_centrality = nx.betweenness_centrality(G)
        closeness_centrality = nx.closeness_centrality(G)
        
        # Create centrality DataFrame
        centrality_df = pd.DataFrame({
            '–¢–µ–º–∞': list(degree_centrality.keys()),
            '–°—Ç–µ–ø–µ–Ω–Ω–∞ —Ü–µ–Ω—Ç—Ä–∞–ª–Ω–æ—Å—Ç': list(degree_centrality.values()),
            '–ü–æ—Å—Ä–µ–¥–Ω–∏—á–µ—Å–∫–∞ —Ü–µ–Ω—Ç—Ä–∞–ª–Ω–æ—Å—Ç': list(betweenness_centrality.values()),
            '–ë–ª–∏–∑–æ—Å—Ç–Ω–∞ —Ü–µ–Ω—Ç—Ä–∞–ª–Ω–æ—Å—Ç': list(closeness_centrality.values())
        }).round(3)
        
        # Sort by degree centrality
        centrality_df = centrality_df.sort_values('–°—Ç–µ–ø–µ–Ω–Ω–∞ —Ü–µ–Ω—Ç—Ä–∞–ª–Ω–æ—Å—Ç', ascending=False)
        
        st.subheader("–¢–æ–ø 15 —Ç–µ–º–∏ –ø–æ —Ü–µ–Ω—Ç—Ä–∞–ª–Ω–æ—Å—Ç")
        st.dataframe(centrality_df.head(15), width='stretch')
        
        # Show network statistics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("–í—ä–∑–ª–∏ –≤ –º—Ä–µ–∂–∞—Ç–∞", G.number_of_nodes())
        
        with col2:
            st.metric("–í—Ä—ä–∑–∫–∏ –≤ –º—Ä–µ–∂–∞—Ç–∞", G.number_of_edges())
        
        with col3:
            density = nx.density(G)
            st.metric("–ü–ª—ä—Ç–Ω–æ—Å—Ç", f"{density:.3f}")
        
        with col4:
            if nx.is_connected(G):
                avg_path = nx.average_shortest_path_length(G)
                st.metric("–°—Ä–µ–¥–Ω–∞ –¥–∏—Å—Ç–∞–Ω—Ü–∏—è", f"{avg_path:.2f}")
            else:
                st.metric("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏", nx.number_connected_components(G))
